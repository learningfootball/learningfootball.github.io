[{"fontsizes": ["6.97"], "fontnames": ["ZBMZDU+LinBiolinumT"], "x1": 35.798, "y1": 761.9512094, "x2": 230.97374059999993, "y2": 777.1530094, "text": "Identifying and Extracting Football Features\nfrom Real-World Media Sources using Only Synthetic Training Data"}, {"fontsizes": ["6.97"], "fontnames": ["ZBMZDU+LinBiolinumT"], "x1": 420.2705677999999, "y1": 761.9512094, "x2": 576.1977619999999, "y2": 768.9250094, "text": "Article, August, 2022, Synthetic Football Training Data"}, {"fontsizes": ["8.97"], "fontnames": ["AKXPHQ+LinLibertineTB"], "x1": 136.652, "y1": 587.8937616000001, "x2": 475.3487936000002, "y2": 596.8601616000001, "text": "Figure 3: Stages - Process of creating the dataset through to training and evaluation."}, {"fontsizes": ["8.97"], "fontnames": ["AKXPHQ+LinLibertineTB"], "x1": 35.798, "y1": 356.0237616, "x2": 301.0223545856, "y2": 419.7851616, "text": "Figure 4: Pitch Markers (KeyPoints) - The field markers are essential\nas they provide vital information (e.g., players location during the\ngame). As shown in Figure 9, the view of the game might only show a\nlimited region (field markers help the machine learning algorithm\nidentify the environmental positions). Consists of 7 horizontal\nlines, 10 vertical lines and 3 arcs."}, {"fontsizes": ["8.97"], "fontnames": ["AKXPHQ+LinLibertineTB"], "x1": 35.798, "y1": 197.5027616, "x2": 302.62346670080007, "y2": 261.2631616, "text": "Figure 5: Resolution - Often features are low-resolution (e.g., play-\ners); usually only taking up a few pixels in the bigger picture. For\ninstance, the image shows a zoomed in view of one of the players\nfrom Figure 1. Note the player is more identifiable when the image\nis considered in context of the surrounding\u2019s (zoomed out versus\nin isolation)."}, {"fontsizes": ["9.17", "8.97"], "fontnames": ["XNLJOV+LinLibertineT", "AKXPHQ+LinLibertineTB"], "x1": 35.459, "y1": 42.961, "x2": 302.43437794399995, "y2": 180.5456, "text": "Only a single architecture is presented here but other models could be\nexplored for further work (see Figure 2). Training times where generally\nin the range of half a day with CUDA acceleration (500 epochs).\nNumber of Epochs and Batch Size .\nExperiment used a batch sizes of 50. We decided to go with batch size of\n50 because a larger batch size gave much smoother loss trends over time,\nwhich made the loss curve a little easier to interpret, especially for initial\nexperiments where we used a small number of epochs. Also, the computer\nfaced no difficulties in performing the training steps when using batch\nsize of 50. Initially we ran quick experiments for combinations of different\narchitectures, batch sizes, optimizer and loss functions using 1-5 epochs.\nFor the final setup, we settled on 500 as the training epoch (during testing\nwe found that after 500 epochs the loss decreased very slowly - see Figure\n8)."}, {"fontsizes": ["8.97"], "fontnames": ["AKXPHQ+LinLibertineTB"], "x1": 310.981, "y1": 340.24876159999997, "x2": 577.8092283519999, "y2": 371.1331616, "text": "Figure 6: Stadium - Complexity and the size of the visual can be ex-\ntended to encapsulate a wide range of visuals, including spotlights,\ncrowds and shadows."}, {"fontsizes": ["8.97", "9.17"], "fontnames": ["AKXPHQ+LinLibertineTB", "XNLJOV+LinLibertineT"], "x1": 310.642, "y1": 97.543, "x2": 577.75220392, "y2": 323.29159999999996, "text": "Limitations The training set is \u2018generated\u2019, so care needs to be taken\nthat the \u2018generated\u2019 data does not \u2018miss\u2019 characteristics that may be\nvisible in real-world data (but not in the generated versions). Also specific\ncases where the image does not contain enough information to identify\npitch markers (e.g., only grass can be seen). If the resolution is low (e.g.,\nFigure 5, it can be difficult to identify player/match details - especially\nwhen groups of players are in close proximity).\nFuture Work Future work would explore \u2018spatial\u2019 models, that is, not\njust about single frame snap-shots but taking into account multiple\nframes to extrapolate and extract extra details (e.g., motion analystics\nand behavioural attributes that maybe difficult or impossible to spot\nusing individual images).\nContinue to extend the dataset and provide an online resource (web-\nbased solution) that can be used by anyone to upload and extract features\nfrom football images (also video). User could download and use these\ndetails for analysis.\nExplore fusing multiple dataset resources together to obtain more ac-\ncurate results, such as, images that record the same football game but\nfrom different cameras and viewing locations. Additional research on\nimproving the keypoint approach, for instance using additional feature\nlocations to improve accuracy [Widya et al. 2018], also the opportunity\nto explore the generation and fusion of other data sources (beyond just\n2d images) as being explored in related fields [Fauzy Othman et al. 2022]."}, {"fontsizes": ["10.91", "9.17"], "fontnames": ["AKXPHQ+LinLibertineTB", "XNLJOV+LinLibertineT"], "x1": 310.706, "y1": 41.749, "x2": 576.439474688, "y2": 83.8650979, "text": "5 Conclusion/Discussion\nThe proposed technique has endless potentials and addresses the lack\nof automated robust, fast and accurate methods for extracting features\nfrom football match images."}]