[{"fontsizes": ["17.22"], "fontnames": ["DSEVJX+LinBiolinumTB"], "x1": 40.70200000000001, "y1": 713.803381, "x2": 571.2978433999998, "y2": 750.9447809999999, "text": "Identifying and Extracting Football Features\nfrom Real-World Media Sources using Only Synthetic Training Data"}, {"fontsizes": ["11.96", "9.96"], "fontnames": ["XNLJOV+LinLibertineT"], "x1": 176.372, "y1": 668.328, "x2": 426.2715456000001, "y2": 693.1351999999999, "text": "Jose Cerqueira Fernandes and Benjamin Kenwright\nHeriot-Watt University"}, {"fontsizes": ["10.91", "9.17"], "fontnames": ["AKXPHQ+LinLibertineTB", "XNLJOV+LinLibertineT"], "x1": 35.459, "y1": 443.038, "x2": 302.56434615200004, "y2": 656.7870979, "text": "Abstract\nReal-world images used for training machine learning algorithms are\noften unstructured and inconsistent. The process of analysing and tag-\nging these images can be costly and error prone (also availability, gaps\nand legal conundrums). However, as we demonstrate in this article, the\npotential to generate accurate graphical images that are indistinguishable\nfrom real-world sources has a multitude of benefits in machine learning\nparadigms. One such example of this is football data from broadcast\nservices (television and other streaming media sources). The football\ngames are usually recorded from multiple sources (cameras and phones)\nand resolutions, not to mention, occlusion of visual details and other\nartefacts (like blurring, weathering and lighting conditions) which make\nit difficult to accurately identify features. We demonstrate an approach\nwhich is able to overcome these limitations using generated tagged and\nstructured images. The generated images are able to simulate a variety\nviews and conditions (including noise and blurring) which may only\noccur sporadically in real-world data and make it difficult for machine\nlearning algorithm to \u2018cope\u2019 with these unforeseen problems in real-data.\nThis approach enables us to rapidly train and prepare a robust solution\nthat accurately extracts features (e.g., spacial locations, markers on the\npitch, player positions, ball location and camera FOV) from real-world\nfootball match sources for analytical purposes."}, {"fontsizes": ["10.91", "9.17", "8.97"], "fontnames": ["AKXPHQ+LinLibertineTB", "XNLJOV+LinLibertineT", "HMZIWF+SFRM0900"], "x1": 35.798, "y1": 396.43600000000004, "x2": 301.01797600000003, "y2": 429.35909790000005, "text": "CCS Concepts\n\u2022 Social and professional topics; \u2022 Software and its engineering \u2192\nSoftware creation and management;"}, {"fontsizes": ["10.91", "9.17"], "fontnames": ["AKXPHQ+LinLibertineTB", "XNLJOV+LinLibertineT"], "x1": 35.798, "y1": 358.316, "x2": 302.5686814808, "y2": 390.97709790000005, "text": "Keywords\ngraphics, machine learning, football, analytics, machine learning, gener-\nating, training, procedural"}, {"fontsizes": ["10.91", "9.17"], "fontnames": ["AKXPHQ+LinLibertineTB", "XNLJOV+LinLibertineT"], "x1": 35.358, "y1": 107.561, "x2": 302.5657301575999, "y2": 350.1670979, "text": "1 Introduction\nManual feature tagging and extraction in machine learning is tedious\n(if not impractical) and error prone. We demonstrate that it is possible\nto perform computer vision feature extraction on raw football game\nimages using a machine learning solution that was trained using only\nsynthetic data. The football community has long enjoyed the benefits of\nusing machine learning techniques to extract and analyze details (from\nindividual player performance to the overall game statistics [Herold et al.\n2019]). Common to use real-world data sources (recordings of live games)\nas they captures details which are vital for analytics. Identifying and\nextracting the features for these analytical processes is often difficult\nand painstaking slow (especially for raw/live football matches). While\nresearchers have tried to improve the methods for tagging and extracting\ninformation from football images, little research has been done on using\nsynthetic models for training the system. We show that it is possible to\nsynthesize data with minimal domain gap (difference between the syn-\nthetic and real-data), so that models trained on synthetic data generalize\nto real in-the-wild datasets.\nWe describe how to combine 3-dimensional graphical models (environ-\nments, objects and players) with a rendering framework to create image\ndatasets with unprecedented realism and diversity. We train a machine\nlearning system using the generated dataset to identify feature such as\nlandmark localizations. We demonstrate that synthetic data can be used\nto accurately locate key features in real-world data as well as open up\nnew approaches where manual labelling would be impossible."}, {"fontsizes": ["6.97"], "fontnames": ["XNLJOV+LinLibertineT", "PJGTKN+LinLibertineTI"], "x1": 35.317, "y1": 42.995999999999995, "x2": 301.0194107084, "y2": 99.3848, "text": "Permission to make digital or hard copies of part or all of this work for personal or classroom use\nis granted without fee provided that copies are not made or distributed for profit or commercial\nadvantage and that copies bear this notice and the full citation on the first page. Copyrights\nfor third-party components of this work must be honored. For all other uses, contact the\nowner/author(s).\nArticle, August, 2022, Synthetic Football Training Data\n\u00a9 2022 Copyright held by the owner/author(s)."}, {"fontsizes": ["8.97"], "fontnames": ["AKXPHQ+LinLibertineTB"], "x1": 310.981, "y1": 282.45076159999996, "x2": 576.4511774079999, "y2": 324.2931616, "text": "Figure 1: Live Image Data - Ability to identify and extrapolate key\nareas from real-world images (football pitch and object markers) in\nreal-time without human intervention (this includes images with\npoor resolution, blurring, artifacts and occluded details)."}, {"fontsizes": ["8.97", "9.17"], "fontnames": ["AKXPHQ+LinLibertineTB", "XNLJOV+LinLibertineT"], "x1": 310.706, "y1": 199.372, "x2": 577.7471675023999, "y2": 265.4926, "text": "Contributions The main contributions of this work are: (1) novel\ntechnique for synthesizing labeled football images for training machine\nlearning algorithms; (2) demonstration of the capability of synthesizing\nfeatures of arbitrary geometries and their corresponding labeled images;\n(3) use of the synthesized data for training machine-learning based fea-\nture parameter extractors; and (4) open source datasets for testing of\nsynthetic training data."}, {"fontsizes": ["10.91", "9.17"], "fontnames": ["AKXPHQ+LinLibertineTB", "XNLJOV+LinLibertineT"], "x1": 310.661, "y1": 36.921, "x2": 577.613432, "y2": 185.6940979, "text": "2 Related Work\nFeature matching machine-learning algorithms require a huge pool of\nlabeled data for proper training, which is often unavailable [Konnik et al.\n2021]. To resolve this shortage generated images can be used in place\nof real-world images. The concept of using generated graphical images\nfor training machine learning systems is not a new one, and has been\nused other areas, such as face analysis [Wood et al. 2021] and feature\nextraction (x-rays images [Konnik et al. 2021]).\nThe most common approach for automatically identifying features in\ncomputer-vision (CV) techniques is to segment the images into distinct\npartitions [Blaschke and Lang 2006; Kaur and Kaur 2014; Zaitoun and\nAqel 2015] which hopefully provide meaning for extracting geometric\ninformation.\nCurrently all of the publications on machine learning and football feature\nextraction have used real-world data as the source for the training models"}]