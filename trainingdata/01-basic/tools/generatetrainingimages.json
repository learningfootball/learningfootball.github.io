{"version":"0.0.2","signiture":"webgpulab","info":"https://webgpu.xbdev.net","date":"2022-06-27T09:05:28.977Z","author":"Kenwright","uniqueid":"mVKRXnyN4cd9yviwZDur0R0F7iuDGx1f","tasks":[{"tabname":"index.js","tabcontents":"/*\n  Lighting (diretional lighting)\n*/\nconsole.log('index.js');\n\ndocument.body.style.margin  = '0';\ndocument.body.style.padding = '0';\n\n/*\nvar script = document.createElement('script');\nscript.type  = 'text/javascript';\nscript.src   = 'https://cdnjs.cloudflare.com/ajax/libs/gl-matrix/2.6.0/gl-matrix-min.js';\ndocument.head.appendChild(script); \n*/\n\nlet pp = await fetch( 'https://cdnjs.cloudflare.com/ajax/libs/gl-matrix/2.6.0/gl-matrix-min.js' );\nlet tt = await pp.text();\n\nvar script = document.createElement('script');\nscript.type  = 'text/javascript';\n//script.src   = 'https://cdnjs.cloudflare.com/ajax/libs/gl-matrix/2.6.0/gl-matrix-min.js';\nscript.innerHTML = tt;\ndocument.head.appendChild(script); \n\n\nconst canvas = document.createElement('canvas');\ndocument.body.appendChild( canvas );\ncanvas.width  = canvas.height = 256;\nconsole.log( canvas.width, canvas.height );\nconst context = canvas.getContext('webgpu');\ncanvas.style.position = 'absolute';\ncanvas.style.left = '0px';\ncanvas.style.top  = '0px';\n\n\n\n\nconst gpu = navigator.gpu;\nconsole.log( 'gpu:', gpu );\n\nconst adapter = await gpu.requestAdapter();\nconst device  = await adapter.requestDevice();\n\nconst presentationSize = [ canvas.clientWidth, canvas.clientHeight  ];\nconst presentationFormat = context.getPreferredFormat(adapter);\nconsole.log( presentationFormat  );\n\ncontext.configure({ device: device,\n                    format: presentationFormat,\n                    size  : presentationSize });\n\n\nvar positions =  new Float32Array([\n   -1,0,1,  -1,0,-1,   1,0,-1,   1,0,1 ]);\n\nvar indices = new Uint32Array([\n    0,1,2,    2,3,0 ]);\n  \nvar colors  = new Float32Array([\n    0,1,0, 0,1,0, 0,1,0,  0,1,0 ]);\n\nvar normals = new Float32Array([\n    0,1,0,  0,1,0,  0,1,0,  0,1,0]);\n\nvar uvs  = new Float32Array([\n    0,0, 1,0, 1,1, 0,1 ]);\n\n\n\n\n\n\nconst positionBuffer = device.createBuffer({\n  size:  positions.byteLength,\n  usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST\n});\n\nconst colorBuffer = device.createBuffer({\n  size:  colors.byteLength,\n  usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST\n});\n\nconst normalBuffer = device.createBuffer({\n  size:  normals.byteLength,\n  usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST\n});\n\nconst uvBuffer = device.createBuffer({\n  size:  uvs.byteLength,\n  usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST\n});\n\nconst indicesBuffer = device.createBuffer({\n  size:  indices.byteLength,\n  usage: GPUBufferUsage.INDEX | GPUBufferUsage.COPY_DST\n});\n\n\ndevice.queue.writeBuffer(positionBuffer, 0, positions);\ndevice.queue.writeBuffer(colorBuffer   , 0, colors   );\ndevice.queue.writeBuffer(normalBuffer  , 0, normals  );\ndevice.queue.writeBuffer(indicesBuffer , 0, indices  );\ndevice.queue.writeBuffer(uvBuffer      , 0, uvs      );\n\nvar vertWGSL = document.getElementById('vertex.wgsl').innerHTML;\nvar fragWGSL = document.getElementById('fragment.wgsl').innerHTML;\n\n\n// ----------------------------------------------------------------\n\nlet textureSampler = device.createSampler({\n     minFilter: \"linear\",\n     magFilter: \"linear\"\n});\n\nconst img = document.createElement(\"img\");\nimg.src = 'https://webgpulab.xbdev.net/var/images/footballfield.jpg';\nawait img.decode();\n\nconst basicTexture = device.createTexture({\n    size: [img.width, img.height, 1],\n    format: presentationFormat , // \"bgra8unorm\",\n    usage:  GPUTextureUsage.COPY_DST | GPUTextureUsage.TEXTURE_BINDING\n});\n\nconst imageCanvas = document.createElement('canvas');\nimageCanvas.width =  img.width;\nimageCanvas.height = img.height;\nconst imageCanvasContext = imageCanvas.getContext('2d');\nimageCanvasContext.drawImage(img, 0, 0, imageCanvas.width, imageCanvas.height);\nconst imageData = imageCanvasContext.getImageData(0, 0, imageCanvas.width, imageCanvas.height);\nlet textureData= new Uint8Array( img.width * img.height * 4);\nfor (let x=0; x<img.width * img.height * 4; x++)\n{\n   textureData[ x ] = imageData.data[ x ];\n}\n\ndevice.queue.writeTexture( { texture: basicTexture },\n            textureData,\n            {   offset     :  0,\n                bytesPerRow:  img.width * 4,\n                rowsPerImage: img.height\n             },\n            [ img.width  ,  img.height,  1  ]   );\n\n\n// ----------------------------------------------------------------\n\n// dynamic world transforms (animate/rotate the shape)\nconst rotation   = [0, 0, 0];\nlet rotateXMat   = mat4.create();\nlet rotateYMat   = mat4.create();\nlet rotateZMat   = mat4.create();\n\n\nprojectionMatrix     = mat4.create();\nconst viewMatrix           = mat4.create();\nviewProjectionMatrix = mat4.create();\nmodelMatrix          = mat4.create();\n\nmat4.perspective(projectionMatrix, Math.PI / 2, canvas.width / canvas.height, 0.1, 10.0)\nmat4.lookAt(viewMatrix, [0, 1.4, 1], [0, 0, 0], [0, 1, 0]);\nmat4.multiply(viewProjectionMatrix, projectionMatrix, viewMatrix);\n\nconst vertexUniformBuffer = device.createBuffer({\n  size: 128,\n  usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST\n});\n\ndevice.queue.writeBuffer(vertexUniformBuffer,   0,  viewProjectionMatrix );\ndevice.queue.writeBuffer(vertexUniformBuffer,   64, modelMatrix          );\n\n// ----------------------------------------------------------------\n\nconst sceneUniformBindGroupLayout = device.createBindGroupLayout({\n  entries: [\n    { binding: 0, visibility: GPUShaderStage.VERTEX,   buffer:  { type: \"uniform\"  }   }, \n    { binding: 1, visibility: GPUShaderStage.FRAGMENT, sampler: { type: \"filtering\"}   },\n    { binding: 2, visibility: GPUShaderStage.FRAGMENT, texture: { sampleType: \"float\",\n                                                                  viewDimension: \"2d\"} } \n  ]\n});\n\nconst uniformBindGroup = device.createBindGroup({\n  layout:   sceneUniformBindGroupLayout,\n  entries: [\n    { binding : 0, resource: { buffer: vertexUniformBuffer } },\n    { binding : 1, resource: textureSampler },\n    { binding : 2, resource: basicTexture.createView()  },\n   ],\n});\n\n// ----------------------------------------------------------------\n\nconst depthTexture = device.createTexture({\n  size   : presentationSize,\n  format : 'depth24plus',\n  usage  : GPUTextureUsage.RENDER_ATTACHMENT,\n});\n\n// ----------------------------------------------------------------\n\n\nconst pipeline = device.createRenderPipeline({\n    layout: device.createPipelineLayout({bindGroupLayouts: [sceneUniformBindGroupLayout]}),\n    vertex:   {  module    : device.createShaderModule({ \n                             code : vertWGSL }),\n                 entryPoint: 'main',\n                 buffers    : [ { arrayStride: 12, attributes: [{ shaderLocation: 0,\n                                                                  format: \"float32x3\",\n                                                                  offset: 0  }]        },\n                                { arrayStride: 12, attributes: [{ shaderLocation: 1,\n                                                                  format: \"float32x3\",\n                                                                  offset: 0  }]        },\n                                { arrayStride: 12, attributes: [{ shaderLocation: 2,\n                                                                  format: \"float32x3\",\n                                                                  offset: 0  }]        },\n                                { arrayStride: 8,  attributes: [{ shaderLocation: 3,\n                                                                  format: \"float32x2\",\n                                                                  offset: 0  }]        }\n                              ]},\n    fragment: {  module    : device.createShaderModule({ \n                             code : fragWGSL,     }),\n                 entryPoint: 'main',\n                 targets: [{  format : presentationFormat  }] },\n    primitive: { topology  : 'triangle-list',\n                 frontFace : \"ccw\",\n                 cullMode  : 'none',\n                 stripIndexFormat: undefined },\n    depthStencil: {\n                 depthWriteEnabled: true,\n                 depthCompare     : 'less',\n                 format           : 'depth24plus' }\n});\n\n// GPURenderPassDescriptor \nconst renderPassDescriptor = { \n      colorAttachments:  [{    \n           view     : undefined, // asign later in frame\n           loadOp:\"clear\", clearValue: { r: 0.0, g: 0.0, b: 0.0, a: 1.0 },\n           storeOp  : 'store' }],\n      depthStencilAttachment: {\n           view: depthTexture.createView(),\n           depthLoadOp:\"clear\", depthClearValue: 1.0,\n           depthStoreOp: 'store',\n           //// // // // // stencilLoadValue: 0,\n           //// // // // // stencilStoreOp: 'store' \n        } \n};\n\n\nsetuptracking();\n\nrotation[1] += 0.1;\n\n// put image in top left to show what the training image looks like\nlet simg = document.createElement('img');\nsimg.id = 'simg';\nsimg.style.position = 'absolute';\nsimg.style.left     = '256px';\nsimg.style.top      = '0px';\nsimg.style.width    = '128px';\nsimg.style.width    = '128px';\ndocument.body.appendChild( simg );\n\nlet ediv = document.createElement('div');\nediv.id = 'ediv';\nediv.style.position = 'absolute';\nediv.style.left     = '128';\nediv.style.top      = '138px';\nediv.style.fontSize = '8pt';\ndocument.body.appendChild( ediv );\n\nvar counter = 0;\n\nfunction frame() {\n\n  // --------------------------------------------------\n  // Update uniform buffer \n\n \n  device.queue.writeBuffer(vertexUniformBuffer,   0,  viewProjectionMatrix );\n\n  \n  //rotation[2] += 0.005;\n  mat4.fromXRotation(rotateXMat, rotation[0]);\n  mat4.fromYRotation(rotateYMat, rotation[1]);\n  mat4.fromZRotation(rotateZMat, rotation[2]);\n\n  mat4.multiply(modelMatrix, rotateYMat,     rotateZMat);\n  mat4.multiply(modelMatrix, modelMatrix,    rotateXMat);\n\n  device.queue.writeBuffer(vertexUniformBuffer, 64, modelMatrix);\n\n  // --------------------------------------------------\n  renderPassDescriptor.colorAttachments[0].view = context.getCurrentTexture().createView();\n\n  const commandEncoder = device.createCommandEncoder();\n\n  const renderPass = commandEncoder.beginRenderPass(renderPassDescriptor);\n  renderPass.setPipeline(pipeline);\n\n  renderPass.setBindGroup(0, uniformBindGroup);\n  renderPass.setVertexBuffer(0, positionBuffer);\n  renderPass.setVertexBuffer(1, colorBuffer);\n  renderPass.setVertexBuffer(2, normalBuffer);\n  renderPass.setVertexBuffer(3, uvBuffer);\n  renderPass.setIndexBuffer(indicesBuffer, 'uint32');\n  renderPass.drawIndexed(6, 1, 0, 0);\n\n  renderPass.end();\n  device.queue.submit([commandEncoder.finish()]);\n\n\n  \n  let idealCoords = drawOverlay();\n  \n  let scrnpng = canvas.toDataURL(\"image/jpeg\"); // alt png\n  //console.log( scrnpng );\n  simg.src = scrnpng;\n\n  counter++;\n  if ( counter % 20 == 0)\n  {\n  let ly = 0.5 + Math.random()*2.5;\n  let lz = 0.5 + Math.random()*0.5;\n  let aspec = (Math.PI / 2) + (-0.1+Math.random()*0.2);\n    \n  mat4.perspective(projectionMatrix, aspec, canvas.width / canvas.height, 0.1, 10.0)\n  mat4.lookAt(viewMatrix, [0, ly, lz], [0, 0, 0], [0, 1, 0]);\n  mat4.multiply(viewProjectionMatrix, projectionMatrix, viewMatrix);\n    \n  rotation[0] = 0 + Math.random()*0.5;\n  rotation[1] = 1 + Math.random()*2;\n  \n  addImageDataList( scrnpng, idealCoords );\n  }\n  \n  //performTraining( simg, idealCoords );\n  \n  // if you want constant updates (animated) - keep refreshing\n  requestAnimationFrame(frame);\n};\n\nframe();\n\nwindow.onmousemove = function(){\n  //console.log('update');\n  //frame();\n}\n\n\n\t \n\t \n\t \n\t \n\t \n\t \n\t \n\t "},{"tabname":"vertex.wgsl","tabcontents":"struct Uniforms {\n  modelViewProjectionMatrix : mat4x4<f32>,\n  modelMatrix               : mat4x4<f32>,\n};\n@binding(0) @group(0) var<uniform> uniforms : Uniforms;\n\nstruct VSOut {\n    @builtin(position) Position: vec4<f32>,\n    @location(0)       color   : vec3<f32>,\n    @location(1)       normal  : vec3<f32>,\n    @location(2)       uvs     : vec2<f32>,\n};\n\n@vertex \nfn main(@location(0) inPos  : vec3<f32>,\n        @location(1) color  : vec3<f32>,\n        @location(2) normal : vec3<f32>,\n        @location(3) uvs    : vec2<f32>) -> VSOut  \n{ \n  var vsOut: VSOut;\n  vsOut.Position = uniforms.modelViewProjectionMatrix * uniforms.modelMatrix * vec4<f32>( inPos, 1.0);\n  vsOut.uvs      = uvs;\n  vsOut.color    = color;\n  vsOut.normal   = (uniforms.modelMatrix * vec4<f32>(normal, 0.0)).xyz;\n  return vsOut;\n\n}\n\t \n\t \n\t \n\t "},{"tabname":"fragment.wgsl","tabcontents":"@group(0) @binding(1) var mySampler: sampler;\n@group(0) @binding(2) var myTexture: texture_2d<f32>;\n\n@fragment\nfn main(@location(0) inColor: vec3<f32>,\n        @location(1) normal : vec3<f32>,\n        @location(2) uvs    : vec2<f32>) -> @location(0) vec4<f32> \n{\n    // return vec4 (rgba)\n    let texCol = textureSample(myTexture, mySampler, uvs );\n\n    // hard code reference direction (z direction)    \n    let dir   = vec3<f32>(0.0, 0.0, 1.0);\n\n    // scale brightness based on the normal vs ref drection\n    let illum = abs( dot( dir, normal ) );\n\n    // use texture for the color (scale it by the illum value)\n    return vec4<f32>( texCol.xyz , 1.0 ); \n}\n\n\t \n\t \n\t \n\t "},{"tabname":"calculateworldpoints.js","tabcontents":"console.log('calculateworldpoints.js');\n\n\n\ncanvas2d  = document.createElement('canvas');\ncanvas2d.width = canvas2d.height = 256;\ndocument.body.appendChild( canvas2d );\ncanvas2d.style['z-index'] = 99999;\ncanvas2d.style.position = 'absolute';\ncanvas2d.style.left = '0px';\ncanvas2d.style.top  = '0px';\n\ncontext2d = canvas2d.getContext('2d');\n\n\nlet pp = await fetch( 'https://cdnjs.cloudflare.com/ajax/libs/gl-matrix/2.6.0/gl-matrix-min.js' );\nlet tt = await pp.text();\n\nvar script = document.createElement('script');\nscript.type  = 'text/javascript';\n//script.src   = 'https://cdnjs.cloudflare.com/ajax/libs/gl-matrix/2.6.0/gl-matrix-min.js';\nscript.innerHTML = tt;\ndocument.head.appendChild(script); \n\ntrackingPointsScreen = [];\ntrackingPointsWorld  = [];\n\nsetuptracking = function()\n{\n  /*\n    Points in pixel coordinates (flat 2d texture)\n  */\n  let trackingPointsTex = [\n    /*\n    [ 32, 21 ],\n    [ 32, 431],\n    [304, 430],\n    [578, 430],\n    [582, 21 ],\n    [305, 21 ]*/\n   [33, 20],\n   [306, 20],\n   [580, 21],\n   [579, 134],\n   [580, 184],\n   [579, 266],\n   [579, 319],\n   [581, 431],\n   [32, 432],\n   [32, 318],\n   [31, 266],\n   [32, 184],\n   [32, 133],\n   [108, 134],\n   [108, 194],\n   [108, 256],\n   [109, 319],\n   [503, 134],\n   [503, 193],\n   [503, 259],\n   [503, 315],\n   [306, 182],\n   [263, 222],\n   [349, 224],\n   [306, 268],\n   [306, 226]\n  ];\n  let sz = [612, 453];\n\n  // plane is at 0 height\n  // test dimensions of the rectangle -1 to 1 (we can calculate the coordinates)\n\n  trackingPointsWorld = [];\n  for (let i=0; i<trackingPointsTex.length; i++)\n  {\n      let z = -1 + 2 * trackingPointsTex[i][0]/sz[0];\n      let y = 0.0;\n      let x = -1 + 2 * trackingPointsTex[i][1]/sz[1];\n      trackingPointsWorld.push( [ x, y, z ] );\n  }\n}// end setuptracking(..)\n\n\ndrawScreenPoint = function(xx, yy, col)\n{\n    context2d.beginPath();\n    // arc(x, y, radius, startAngle, endAngle)\n    context2d.arc(xx, yy,  5,  0, 2*Math.PI );\n    context2d.fillStyle = col;\n    context2d.fill();\n    context2d.lineWidth = 1;\n    context2d.strokeStyle = '#003399';\n    context2d.stroke();\n}\n\n\ndrawOverlay = function()\n{\n  outMatrix = mat4.create();\n  mat4.multiply(outMatrix, viewProjectionMatrix, modelMatrix );\n  //console.log('mat4:', outMatrix );\n  \n  trackingPointsScreen = [];\n  for (let i=0; i<trackingPointsWorld.length; i++)\n  {\n      let v = vec4.create();\n      v[0] = trackingPointsWorld[i][0];\n      v[1] = trackingPointsWorld[i][1];\n      v[2] = trackingPointsWorld[i][2];\n      v[3] = 1.0;\n    \n      let res = vec4.create();\n      vec4.transformMat4(res, v, outMatrix );\n      res[0] /= res[3];\n      res[1] /= res[3];\n      res[2] /= res[3];\n      res[3] /= res[3];\n      // console.log( res );\n    \n      let x = res[0]*0.5 + 0.5;// 0-1\n      let y = res[1]*0.5 + 0.5;//0-1\n    \n      x *= canvas2d.width;\n      y  = (y-1.0) * -canvas2d.height;\n    \n      trackingPointsScreen.push( [x, y] );\n  }\n  \n  context2d.clearRect(0, 0, canvas2d.width, canvas2d.height);\n  \n  // console.log('trackingPointsScreen:', trackingPointsScreen );\n  for (let i=0; i<trackingPointsScreen.length; i++)\n  {\n    let sx = trackingPointsScreen[i][0];\n    let sy = trackingPointsScreen[i][1];\n\n    drawScreenPoint( sx, sy, 'orange' );\n    /*\n    context2d.beginPath();\n    // arc(x, y, radius, startAngle, endAngle)\n    context2d.arc(sx, sy,  5,  0, 2*Math.PI );\n    context2d.fillStyle = 'orange';\n    context2d.fill();\n    context2d.lineWidth = 1;\n    context2d.strokeStyle = '#003399';\n    context2d.stroke();\n    */\n  }\n  \n  return trackingPointsScreen; // [x,y]\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t \n\t \n\t \n\t "},{"tabname":"trainingdata.js","tabcontents":"console.log('trainingdata.js');\n\ngenerateNumberImages = 20;\n\nlet zprom = await fetch( 'https://cdnjs.cloudflare.com/ajax/libs/jszip/3.6.0/jszip.min.js' );\nlet zcont = await zprom.text();\n\nvar script = document.createElement('script');\nscript.type = 'text/javascript';\nscript.innerHTML = zcont;\ndocument.head.appendChild(script); \n\nmyzip = new JSZip();\nconsole.log('myzip:', myzip );\n\nlet myzipfolder = myzip.folder(\"trainingimages\");\n\nimgcounter = 0;\ncsvfiledata = '';\n\n\n\naddImageDataList = async function( imgdata, points )\n{\n  //console.log('myzip:..', myzip );\n  let imgfilename = 'img' + imgcounter + '.jpg';\n  imgcounter++;\n  \n  if ( imgcounter > 100 ) return;\n  \n  if ( imgcounter == 100 )\n  {\n    createZip();\n    return;\n  }\n  \n\n  \n  csvfiledata += `${imgfilename}, ${points.flat()}` + '\\n';\n  \n  // console.log('csvfile:',  csvfile);\n  \n  // You're generating a data uri, which has schema, mime-type etc before the actual base64 data data:[<MIME-type>][;charset=<encoding>][;base64],<data>. You'll have to remove all the content before the data then use it.\n  //myzipfolder.file( imgfilename, imgdata );\n\n  myzipfolder.file(imgfilename, imgdata.substr(imgdata.indexOf(',')+1), {base64: true});\n}\n\n\ncreateZip = async function()\n{\n   if ( document.getElementById('downloadlink') )\n   {\n     return;\n   }\n  //return;\n   console.log('creating zip..');\n  \n   myzip.file(\"imagepoints.csv\", csvfiledata);\n\n   //myzip.generateAsync({type: \"blob\"}).then(function(content) {\n  \n   let content = await myzip.generateAsync({type: \"blob\"});\n   \n        //console.log( 'zipfile contents:', String(content) );\n        // var content = myzip.generate();\n  \n        var a = document.createElement(\"a\");\n        document.body.appendChild( a );\n        a.id = 'downloadlink';\n        a.style.position = 'absolute';\n        a.style.bottom = '20px';\n        a.style.left   = '10px';\n        a.innerHTML = 'Click to Download Training Data Zip';\n     \n        var file = new Blob([ content ], {type: 'octet/stream'});\n        a.href = URL.createObjectURL( file );\n        a.download = 'trainingdata.zip';\n        a.style['font-size'] = '20pt';\n   //});\n\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t "}]}